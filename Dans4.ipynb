{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import xlrd\n",
    "import os\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from datetime import datetime, date, timedelta\n",
    "import nltk\n",
    "#from flatten_json import flatten\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stu/code/dans\n"
     ]
    }
   ],
   "source": [
    "%cd /home/stu/code/dans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_res = \"API_results_\" + time.strftime(\"%Y%m%d\") + \".csv\"\n",
    "file_res = \"API_results_20210822.csv\"\n",
    "my_df = pd.read_csv(file_res)\n",
    "\n",
    "## Categories\n",
    "#my_df[\"Categories\"]\n",
    "# Willnjust keep 2 levels.\n",
    "my_df[\"Categories\"] = my_df[\"Categories\"].map(eval, na_action='ignore')\n",
    "new_df = my_df[\"Categories\"].apply(pd.Series)\n",
    "my_df[\"Categories\"] = new_df[0].apply(pd.Series).UrlFriendlyName\n",
    "my_df[\"Sub_Categories\"] = new_df[1].apply(pd.Series).UrlFriendlyName\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Reviews\n",
    "my_df[\"Reviews\"] = my_df[\"Reviews\"].map(eval,  na_action='ignore')\n",
    "# Try with first 2 reviews\n",
    "new_df = my_df[\"Reviews\"].apply(pd.Series)\n",
    "# First\n",
    "my_df[\"Review1_auth\"] = new_df[0].apply(pd.Series).author.apply(pd.Series).Value\n",
    "my_df[\"Review1_authorcontent\"] = new_df[0].apply(pd.Series).authorcontent.apply(pd.Series).Value\n",
    "my_df[\"Review1_points\"] = new_df[0].apply(pd.Series).points.apply(pd.Series).Value\n",
    "my_df[\"Review1_source\"] = new_df[0].apply(pd.Series).source.apply(pd.Series).Value\n",
    "my_df[\"Review1_text\"] = new_df[0].apply(pd.Series).text.apply(pd.Series).Value\n",
    "my_df[\"Review1_vintage\"] = new_df[0].apply(pd.Series).vintage.apply(pd.Series).Value\n",
    "# Second\n",
    "my_df[\"Review2_auth\"] = new_df[1].apply(pd.Series).author.apply(pd.Series).Value\n",
    "my_df[\"Review2_authorcontent\"] = new_df[1].apply(pd.Series).authorcontent.apply(pd.Series).Value\n",
    "my_df[\"Review2_points\"] = new_df[1].apply(pd.Series).points.apply(pd.Series).Value\n",
    "my_df[\"Review2_source\"] = new_df[1].apply(pd.Series).source.apply(pd.Series).Value\n",
    "my_df[\"Review2_text\"] = new_df[1].apply(pd.Series).text.apply(pd.Series).Value\n",
    "my_df[\"Review2_vintage\"] = new_df[1].apply(pd.Series).vintage.apply(pd.Series).Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional details\n",
    "my_df[\"AdditionalDetails\"] = my_df[\"AdditionalDetails\"].map(eval,  na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = copy.deepcopy(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail = full_df[full_df[\"IsForDelivery\"]][[\"Stockcode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't use nested lists of JSON objects in pd.json_normalize\n",
    "my_df = my_df.explode(column=\"AdditionalDetails\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = pd.DataFrame(pd.json_normalize(my_df[\"AdditionalDetails\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del add_df[\"DisplayName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([my_df,add_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pivot(index='Stockcode',columns='Name', values='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mydf.csv\")\n",
    "df = pd.read_csv(\"mydf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.merge(full_df, df, on='Stockcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv(\"newdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (96,97,98,137,140,181) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "newdf = pd.read_csv(\"newdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gives = newdf[['Stockcode','Description','webproductname','Prices.singleprice.Value','Prices.promoprice.Value','Prices.promoprice.BeforePromotion','Prices.promoprice.AfterPromotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gives = gives[gives.webproductname.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives = gives[gives['Stockcode'].str.contains(\"MYSTERY\")]\n",
    "gives = gives[gives[\"Description\"].str.contains(\"Wraps\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gives = gives[~gives[\"webproductname\"].str.contains(\"Wraps\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>Description</th>\n",
       "      <th>webproductname</th>\n",
       "      <th>Prices.singleprice.Value</th>\n",
       "      <th>Prices.promoprice.Value</th>\n",
       "      <th>Prices.promoprice.BeforePromotion</th>\n",
       "      <th>Prices.promoprice.AfterPromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MYSTERY437</td>\n",
       "      <td>Under Wraps Western&lt;br&gt;Australia Cabernet... ...</td>\n",
       "      <td>Alkoomi Blackbutt Cabernet Merlot Cabernet Franc</td>\n",
       "      <td>59.99</td>\n",
       "      <td>30.0</td>\n",
       "      <td>59.99</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MYSTERY411</td>\n",
       "      <td>Under Wraps Hawkes Bay Syrah&lt;br&gt;2010  750mL</td>\n",
       "      <td>Craggy Range Le Sol Syrah 2010</td>\n",
       "      <td>155.99</td>\n",
       "      <td>79.9</td>\n",
       "      <td>155.99</td>\n",
       "      <td>79.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MYSTERY459</td>\n",
       "      <td>Under Wraps Great Southern&lt;br&gt;Cabernet Sauvig...</td>\n",
       "      <td>Forest Hill Block 5 Caberent Sauvignon</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MYSTERY378</td>\n",
       "      <td>Under Wraps Western&lt;br&gt;Australia Cabernet... ...</td>\n",
       "      <td>Peos Estate Cab Sauv</td>\n",
       "      <td>22.99</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.99</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MYSTERY540</td>\n",
       "      <td>Under Wraps Clare Valley&lt;br&gt;Cabernet Sauvigno...</td>\n",
       "      <td>Jim Barry The Benbournie Cabernet Sauvignon 2014</td>\n",
       "      <td>35.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MYSTERY242</td>\n",
       "      <td>Under Wraps Barossa Merlot&lt;br&gt;2017  750mL</td>\n",
       "      <td>Gibson My Darling Merlot 2014</td>\n",
       "      <td>24.99</td>\n",
       "      <td>14.9</td>\n",
       "      <td>24.99</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MYSTERY594</td>\n",
       "      <td>Under Wraps Heathcote Shiraz&lt;br&gt;Cabernet 2017...</td>\n",
       "      <td>Feathered Friends Heathcote Shiraz Cabernet 2015</td>\n",
       "      <td>25.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MYSTERY196</td>\n",
       "      <td>Under Wraps Yarra Valley&lt;br&gt;Chardonnay 2018  ...</td>\n",
       "      <td>Yarra Trail Yarra Valley Chardonnay 2016</td>\n",
       "      <td>31.99</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.99</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stockcode                                        Description  \\\n",
       "0  MYSTERY437   Under Wraps Western<br>Australia Cabernet... ...   \n",
       "1  MYSTERY411        Under Wraps Hawkes Bay Syrah<br>2010  750mL   \n",
       "2  MYSTERY459   Under Wraps Great Southern<br>Cabernet Sauvig...   \n",
       "3  MYSTERY378   Under Wraps Western<br>Australia Cabernet... ...   \n",
       "4  MYSTERY540   Under Wraps Clare Valley<br>Cabernet Sauvigno...   \n",
       "5  MYSTERY242          Under Wraps Barossa Merlot<br>2017  750mL   \n",
       "6  MYSTERY594   Under Wraps Heathcote Shiraz<br>Cabernet 2017...   \n",
       "7  MYSTERY196   Under Wraps Yarra Valley<br>Chardonnay 2018  ...   \n",
       "\n",
       "                                     webproductname  Prices.singleprice.Value  \\\n",
       "0  Alkoomi Blackbutt Cabernet Merlot Cabernet Franc                     59.99   \n",
       "1                    Craggy Range Le Sol Syrah 2010                    155.99   \n",
       "2            Forest Hill Block 5 Caberent Sauvignon                     30.00   \n",
       "3                              Peos Estate Cab Sauv                     22.99   \n",
       "4  Jim Barry The Benbournie Cabernet Sauvignon 2014                     35.88   \n",
       "5                     Gibson My Darling Merlot 2014                     24.99   \n",
       "6  Feathered Friends Heathcote Shiraz Cabernet 2015                     25.00   \n",
       "7          Yarra Trail Yarra Valley Chardonnay 2016                     31.99   \n",
       "\n",
       "   Prices.promoprice.Value  Prices.promoprice.BeforePromotion  \\\n",
       "0                     30.0                              59.99   \n",
       "1                     79.9                             155.99   \n",
       "2                      NaN                                NaN   \n",
       "3                     15.0                              22.99   \n",
       "4                      NaN                                NaN   \n",
       "5                     14.9                              24.99   \n",
       "6                     15.0                              25.00   \n",
       "7                     15.0                              31.99   \n",
       "\n",
       "   Prices.promoprice.AfterPromotion  \n",
       "0                              30.0  \n",
       "1                              79.9  \n",
       "2                               NaN  \n",
       "3                              15.0  \n",
       "4                               NaN  \n",
       "5                              14.9  \n",
       "6                              15.0  \n",
       "7                              15.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.merge(gives, avail, left_on='Stockcode', right_on=\"Stockcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep =['Categories',\n",
    " 'Stockcode',\n",
    " 'PackageSize',\n",
    " 'Prices.inanysixprice.Message',\n",
    " 'Prices.inanysixprice.Value',\n",
    " 'Sub_Categories',\n",
    " 'Review1_auth',\n",
    " 'Review1_points',\n",
    " 'Review1_source',\n",
    " 'awardwinner',\n",
    " 'glutenfree',\n",
    " 'preservativefree',\n",
    " 'varietal',\n",
    " 'webalcoholpercentage',\n",
    " 'webbottleclosure',\n",
    " 'webcountryoforigin',\n",
    " 'webfoodmatch',\n",
    " 'webisorganic',\n",
    " 'webisvegan',\n",
    " 'webliquorsize',\n",
    " 'webmaincategory',\n",
    " 'webregionoforigin',\n",
    " 'webstateoforigin',\n",
    " 'webtotalreviewcount',\n",
    " 'webwinebody',\n",
    " 'webwinestyle']                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep1 =['Categories',\n",
    " 'Stockcode',\n",
    " 'PackageSize',\n",
    " 'RichDescription',\n",
    " 'Review1_text',\n",
    " 'Review2_text',\n",
    " 'Prices.inanysixprice.Message',\n",
    " 'Prices.inanysixprice.Value',\n",
    " 'Sub_Categories',\n",
    " 'Review1_auth',\n",
    " 'Review1_points',\n",
    " 'Review1_source',\n",
    " 'awardwinner',\n",
    " 'glutenfree',\n",
    " 'preservativefree',\n",
    " 'varietal',\n",
    " 'webalcoholpercentage',\n",
    " 'webbottleclosure',\n",
    " 'webcountryoforigin',\n",
    " 'webdescriptionshort',\n",
    " 'webfoodmatch',\n",
    " 'webisorganic',\n",
    " 'webisvegan',\n",
    " 'webliquorsize',\n",
    " 'webmaincategory',\n",
    " 'webregionoforigin',\n",
    " 'webstateoforigin',\n",
    " 'webtotalreviewcount',\n",
    " 'webwinebody',\n",
    " 'webwinestyle']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#check = pd.json_normalize(my_df[\"AdditionalDetails\"]).pivot(columns='Name')\n",
    "\n",
    "#check.to_csv(\"check.csv\")\n",
    "\n",
    "#check['Value']\n",
    "#my_df[\"AdditionalDetails\"].apply(pd.Series.explode)\n",
    "\n",
    "########### Would likely want ot save to DB at this tome/.\n",
    "\n",
    "#In excel: =TEXTJOIN(\"','\",TRUE,A1:CF1)\n",
    "#keep = ['Categories','BackorderMessage','varietal','DeliveryOptionsInfo','SavedLists','Stockcode','PackageSize','RichDescription','StockOnHand','UrlFriendlyName','IsDeliveryOnly','Prices.inanysixprice.Value','Prices.caseprice.Value','Prices.singleprice.Value','Inventory.availableinventoryqty','Prices.promoprice.Message','Prices.promoprice.Value','Prices.promoprice.PreText','Prices.promoprice.BeforePromotion','Prices.promoprice.AfterPromotion','Sub_Categories','Review1_auth','Review1_authorcontent','Review1_source','Review1_points','Review1_text','Review1_vintage','awardwinner','brewery','corkscoreeligible','countryoforigin','dm_stockcode','image1','image2','standarddrinks','webalcoholpercentage','webaverageproductrating','webbadgescollection','webbottleclosure','webcountryoforigin','webdescriptionshort','webdsvflag','webfoodmatch','webisvegan','weblangtonsclassification','webliquorsize','webmaincategory','webmaxquantity','webminquantity','webpacksizecase','webpacktype','webpresaleenddate','webpresaleflag','webpresalemarketlaunchdate','webpresalemdmmaxqtylimit','webpresaleorderreleasedate','webpresalestartdate','webpresaleusermaxqtylimit','webproductcanbechilled','webproductname','webproductsale','webproducttype','webpromomdmmessage','webpromomessage','webpromomessageenddt','webpromomessagestartdt','webpromosecondmesgenddt','webpromosecondmesgstartdt','webpromosecondmessage','webpromotionalbundle','webregionoforigin','webstateoforigin','webtotalreviewcount','webvideourl','webvintagecurrent','webvintagenote','webwinebody','webwinemaker','webwinestyle']\n",
    "#keep = ['Categories','BackorderMessage','Description','DeliveryOptionsInfo','SavedLists','Stockcode','PackageSize','StockOnHand','UrlFriendlyName','IsDeliveryOnly','Prices.inanysixprice.Value','Prices.caseprice.Value','Prices.singleprice.Value','Inventory.availableinventoryqty','Prices.promoprice.Message','Prices.promoprice.Value','Prices.promoprice.PreText','Prices.promoprice.BeforePromotion','Prices.promoprice.AfterPromotion','Sub_Categories','Review1_auth','Review1_authorcontent','Review1_source','Review1_points','Review1_text','Review1_vintage','awardwinner','brewery','corkscoreeligible','countryoforigin','dm_stockcode','image1','image2','standarddrinks','webalcoholpercentage','webaverageproductrating','webbadgescollection','webbottleclosure','webcountryoforigin','webdescriptionshort','webdsvflag','webfoodmatch','webisvegan','weblangtonsclassification','webliquorsize','webmaincategory','webmaxquantity','webminquantity','webpacksizecase','webpacktype','webpresaleenddate','webpresaleflag','webpresalemarketlaunchdate','webpresalemdmmaxqtylimit','webpresaleorderreleasedate','webpresalestartdate','webpresaleusermaxqtylimit','webproductcanbechilled','webproductname','webproductsale','webproducttype','webpromomdmmessage','webpromomessage','webpromomessageenddt','webpromomessagestartdt','webpromosecondmesgenddt','webpromosecondmesgstartdt','webpromosecondmessage','webpromotionalbundle','webregionoforigin','webstateoforigin','webtotalreviewcount','webvideourl','webvintagecurrent','webvintagenote','webwinebody','webwinemaker','webwinestyle']\n",
    "# Timmed version\n",
    "#### OLD KEEP\n",
    "#keep = ['Description','Stockcode','PackageSize','Prices.inanysixprice.Value','Prices.caseprice.Value','Prices.singleprice.Value','Prices.promoprice.Message','Prices.promoprice.Value','Prices.promoprice.PreText','Sub_Categories','Review1_auth','Review1_points','Review1_vintage','awardwinner','countryoforigin','standarddrinks','webalcoholpercentage','webaverageproductrating','webbadgescollection','webbottleclosure','webcountryoforigin','webdescriptionshort','webdsvflag','webfoodmatch','webisvegan','weblangtonsclassification','webliquorsize','webmaincategory','webpacksizecase','webpacktype','webregionoforigin','webstateoforigin','webvintagecurrent','webvintagenote','webwinebody','webwinestyle']\n",
    "# Now Keep them.\n",
    "kept = newdf[keep]\n",
    "#kept.to_csv('fri_big_run_kept.csv')\n",
    "kept.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept.to_csv(\"kept.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text to TDIF\n",
    "#'webdescriptionshort',\n",
    "#'RichDescription',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kept = pd.read_csv(\"kept.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "known = kept\n",
    "known.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ONE HOT ENCODED\n",
    "##### First I split into numeric and nominal. OHE the nominal\n",
    "exclude_col = known.select_dtypes(include=np.number).columns.tolist() + [\"Stockcode\"]\n",
    "my_df_num = known[exclude_col]\n",
    "my_df_cat = known.drop(exclude_col, axis=1)\n",
    "#my_df_cat.to_csv(\"FIN.csv\")\n",
    "my_df_cat_ohe = pd.get_dummies(my_df_cat)\n",
    "my_df_ohe = pd.concat([my_df_num,my_df_cat_ohe], axis=1)\n",
    "my_df_ohe = my_df_ohe.fillna(0)\n",
    "my_df_ohe = my_df_ohe.replace(np.nan, 0)\n",
    "\n",
    "# Drop duplicates #TODO check whats better to keep\n",
    "my_df_ohe = my_df_ohe.loc[:,~my_df_ohe.columns.duplicated()]\n",
    "# Clean up names\n",
    "my_df_ohe.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in my_df_ohe.columns.values]\n",
    "\n",
    "myst  = my_df_ohe[my_df_ohe.Stockcode.str.contains(\"MYSTERY\")]\n",
    "known  = my_df_ohe[~my_df_ohe.Stockcode.str.contains(\"MYSTERY\")]\n",
    "\n",
    "myst_nn = myst.drop(\"Stockcode\", axis=1)\n",
    "known_nn = known.drop(\"Stockcode\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# Create the k-NN model using k=5\n",
    "nn_abs = NearestNeighbors(n_neighbors=1, algorithm='auto')\n",
    "\n",
    "# Fit it\n",
    "nn_abs.fit(known_nn)\n",
    "\n",
    "#distance, matches = nn_abs.kneighbors(myst_nn.iloc[[9]], 2, return_distance=True)\n",
    "#matches\n",
    "\n",
    "#known[\"Stockcode\"].iloc[matches[0]]\n",
    "\n",
    "#myst['Stockcode'].iloc[[9]]\n",
    "#Now, tokenise each descition.\n",
    "#MAGIC TIME\n",
    "\n",
    "#myst.iloc[[9]].to_csv(\"myst.csv\")\n",
    "#myst_nn.iloc[[9]].to_csv(\"myst_nn.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#known.iloc[matches[0]].to_csv(\"known.csv\")\n",
    "#known_nn.iloc[matches[0]].to_csv(\"known_nn.csv\")\n",
    "\n",
    "results_wine = []\n",
    "\n",
    "for index in range(len(myst.index)):\n",
    "    distance, matches = nn_abs.kneighbors(myst_nn.iloc[[index]], 1, return_distance=True)\n",
    "    results_wine.append(\n",
    "        {\n",
    "            'Mystery': \"https://www.danmurphys.com.au/product/\" + str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Mystery Stockcode': str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Matched': \"https://www.danmurphys.com.au/product/\" + str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Matched Stockcode':  str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Distance': str(distance[0][0])\n",
    "            \n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "matched = pd.DataFrame(results_wine)\n",
    "\n",
    "#def create_clickable_id(id):\n",
    "#    url_template= '''<a href=\"../../link/to/{id}\" target=\"_blank\">{id}</a>'''.format(id=id)\n",
    "#    return url_template\n",
    "\n",
    "#matched['Mystery'] = matched['Mystery'].apply(create_clickable_id)\n",
    "#matched['Matched'] = matched['Matched'].apply(create_clickable_id)\n",
    "\n",
    "#file_match = \"matched_results_\" + time.strftime(\"%Y%m%d\") + \".csv\"\n",
    "\n",
    "#matched.to_html(\"matched.html\")\n",
    "\n",
    "\n",
    "\n",
    "#matched.to_csv(\"matched_sun_1.csv\")\n",
    "\n",
    "#matches = nn_abs.kneighbors(myst_nn.iloc[[3]], 2, return_distance=False)\n",
    "#known[\"Stockcode\"].iloc[matches[0]]\n",
    "\n",
    "#myst['Stockcode'].iloc[[3]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matched.to_csv(\"Sat_pm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Now just need to join back with the stockcode, and we've got a working MVP..\n",
    "promos = newdf[newdf.Stockcode.str.contains(\"MYSTERY\")][['Stockcode','webproductname','Prices.singleprice.Value','Prices.promoprice.Value']]\n",
    "cutdown = newdf[['Stockcode','Description','producttitle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(matched, promos, left_on='Mystery Stockcode', right_on='Stockcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(final, cutdown, left_on='Matched Stockcode', right_on='Stockcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(final, avail, left_on='Mystery Stockcode', right_on=\"Stockcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[[\"Mystery\",\"Matched\",\"Distance\",\"webproductname\",\"Prices.singleprice.Value\",\"Prices.promoprice.Value\",\"Description\",\"producttitle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Savings'] = final[\"Prices.singleprice.Value\"] - final[\"Prices.promoprice.Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[\"MatchLevel\"] = np.where(final['Distance'].astype(float) < 1.8, \"Good\", \"Poor\")\n",
    "final = final.sort_values(['MatchLevel', 'Savings'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[final.MatchLevel.str.contains(\"Good\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clickable(val):\n",
    "    # target _blank to open new window\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "final = final.style.format({'Mystery': make_clickable,'Matched': make_clickable,})\\\n",
    "                   .bar(subset=['Savings'], align='mid', color=['#5fba7d'])\\\n",
    "                   .bar(subset=['Savings'], align='mid', color=['#5fba7d'])\\\n",
    "                   .hide_index()\\\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#final = final.style.format({'Mystery': make_clickable,'Matched': make_clickable,})\n",
    "#final = final.style.format({'Matched': make_clickable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing HTML Content\n",
    "heading = '<h1> Matched wines</h1>'\n",
    "subheading = '<h3> Results sub header </h3>'\n",
    "# Using .now() from datetime library to add Time stamp\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "header = '<div class=\"top\">' + heading + subheading +'</div>'\n",
    "footer = '<div class=\"bottom\"> <h3> This Report has been Generated on'+ current_time +'</h3> </div>'\n",
    "content = final\n",
    "# Concating everything to a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = header + content.render() + footer\n",
    "# Writing the file\n",
    "with open('report.html','w+') as file:\n",
    "    file.write(html)\n",
    "    #file.write(content)\n",
    "    #file.write(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Styler' object has no attribute 'to_html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b095a27a560d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Styler' object has no attribute 'to_html'"
     ]
    }
   ],
   "source": [
    "#final.to_html(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = \"Matched_results_\" + time.strftime(\"%Y%m%d\") + \".html\"\n",
    "f=open(final_res,\"w\")\n",
    "f.write(final.render()) # df is the styled dataframe\n",
    "f.close()\n",
    "#final.to_html(final_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now any easy ones just matching descirptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = newdf[keep1]\n",
    "#kept.to_csv('fri_big_run_kept.csv')\n",
    "newdf['Review1_text'] = full_df['Review1_text']\n",
    "newdf['Review2_text'] = full_df['Review2_text']\n",
    "\n",
    "kept.reset_index(drop=True, inplace=True)\n",
    "myst  = kept[kept.Stockcode.str.contains(\"MYSTERY\")]\n",
    "known  = kept[~kept.Stockcode.str.contains(\"MYSTERY\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_match = pd.merge(myst[myst['RichDescription'].notna()], known, on=['RichDescription'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdesc_match = pd.merge(myst[myst['webdescriptionshort'].notna()], known, on=['webdescriptionshort'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_match = pd.merge(myst[myst['Review1_text'].notna()], known, on=['Review1_text'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev1_match = pd.merge(myst[myst['Review2_text'].notna()], known, on=['Review2_text'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = desc_match.append(webdesc_match).append(rev_match).append(rev1_match).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = text_match[['Stockcode_x','Stockcode_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Now just need to join back with the stockcode, and we've got a working MVP..\n",
    "#promos = newdf[newdf.Stockcode.str.contains(\"MYSTERY\")][['Stockcode','webproductname','Prices.singleprice.Value','Prices.promoprice.Value']]\n",
    "#cutdown = newdf[['Stockcode','Description','producttitle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = pd.merge(text_match, newdf, left_on='Stockcode_x', right_on='Stockcode')[['Stockcode_x','Stockcode_y','Description', 'Prices.singleprice.Value','Prices.promoprice.Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = pd.merge(text_match, newdf, left_on='Stockcode_y', right_on='Stockcode')[['Stockcode_x','Stockcode_y','Description_y', 'Prices.singleprice.Value_x','Prices.promoprice.Value_x']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match['Savings'] = text_match[\"Prices.singleprice.Value_x\"] - text_match[\"Prices.promoprice.Value_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = text_match.sort_values(['Savings'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match.to_csv(\"Text_match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Fuzzy\n",
    "#https://towardsdatascience.com/how-to-do-fuzzy-matching-in-python-pandas-dataframe-6ce3025834a6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to try and do the NLP Work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text to TFIDF\n",
    "#'webdescriptionshort',\n",
    "#'RichDescription',\n",
    "keep1 =['Stockcode',\n",
    " 'webdescriptionshort',\n",
    "'RichDescription']     \n",
    "#keep1 =[\n",
    "# 'webdescriptionshort',\n",
    "#'RichDescription','Review1_text','Review2_text']     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = newdf[keep1]\n",
    "#kept.to_csv('fri_big_run_kept.csv')\n",
    "kept.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "myst_nn  = kept[kept.Stockcode.str.contains(\"MYSTERY\")]\n",
    "known_nn  = kept[~kept.Stockcode.str.contains(\"MYSTERY\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using http://mlbernauer.github.io/R/20160131-document-retrieval-sklearn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding in tfidf for description, and then dropping the columns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#transformer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "#v = TfidfVectorizer(ngram_range=(2, 3))\n",
    "#x = v.fit_transform(kept['RichDescription'].values.astype('U'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer for webdescriptionshort, max_df is set to 0.5, we only want\n",
    "# to include terms that appear in less tha 50% of the documents (i.e. rare terms)\n",
    "web_tfidf_vectorizer = TfidfVectorizer(max_features=1000000, use_idf=True,ngram_range=(1, 3))\n",
    "\n",
    "# Create vectorizer for , RichDescriptions max_df is set to 0.5, we only want \n",
    "# to include terms that appear in less than 50% of the documents (i.e. rare terms)\n",
    "rich_tfidf_vectorizer = TfidfVectorizer(max_features=1000000, use_idf=True,ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Weights for both\n",
    "tfidf_weights_web = web_tfidf_vectorizer.fit_transform(kept['webdescriptionshort'].values.astype('U'))\n",
    "tfidf_weights_rich = rich_tfidf_vectorizer.fit_transform(kept['RichDescription'].values.astype('U'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names for Abstract and Title models\n",
    "tfidf_features_web = web_tfidf_vectorizer.get_feature_names()\n",
    "tfidf_features_rich = rich_tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model to return 5 closest neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Create the k-NN model using k=5\n",
    "nn_web = NearestNeighbors(n_neighbors=1, algorithm='auto')\n",
    "nn_rich = NearestNeighbors(n_neighbors=1, algorithm='auto')\n",
    "\n",
    "# Fit the models to the TF-IDF weights matrix\n",
    "nn_fitted_web = nn_web.fit(tfidf_weights_web)\n",
    "nn_fitted_rich = nn_rich.fit(tfidf_weights_rich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_papers(row, kNNmodel, tfidf_weights, tfidf_features, papers):\n",
    "    #keywords = get_top_features(row, tfidf_weights, tfidf_features)\n",
    "    dist,idx = kNNmodel.kneighbors(tfidf_weights[row,:])\n",
    "    idx = list(idx[0])\n",
    "    return {'Wines':kept.iloc[idx]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(rownum, weights, features, top_k=10):\n",
    "    weight_vec = weights.toarray()[rownum,:]\n",
    "    top_idx = np.argsort(weight_vec)[::-1][:top_k]\n",
    "    return [features[i] for i in top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1115], dtype='int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept.index[kept['Stockcode'] == 'MYSTERY265']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1115], dtype='int64')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept.index[kept['Stockcode'] == 'MYSTERY265']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([5354], dtype='int64')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.index[df['Stockcode'] == 'MYSTERY265']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>webdescriptionshort</th>\n",
       "      <th>RichDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>MYSTERY265</td>\n",
       "      <td>&lt;p&gt;The fruit for this iconic wine is handpicke...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Stockcode                                webdescriptionshort  \\\n",
       "1115  MYSTERY265  <p>The fruit for this iconic wine is handpicke...   \n",
       "\n",
       "     RichDescription  \n",
       "1115             NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find_nearest_papers(1, nn_fitted_abs, tfidf_weights_abs, tfidf_features_abs, papers)['papers']\n",
    "find_nearest_papers(1115, nn_fitted_web, tfidf_weights_web, tfidf_features_web, kept)['Wines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>webdescriptionshort</th>\n",
       "      <th>RichDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>943434</td>\n",
       "      <td>Dark and focused, filled with juicy and vibran...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stockcode                                webdescriptionshort  \\\n",
       "54    943434  Dark and focused, filled with juicy and vibran...   \n",
       "\n",
       "   RichDescription  \n",
       "54             NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find_nearest_papers(1, nn_fitted_abs, tfidf_weights_abs, tfidf_features_abs, papers)['papers']\n",
    "find_nearest_papers(1115, nn_fitted_rich, tfidf_weights_rich, tfidf_features_rich, kept)['Wines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wine_nlp = []\n",
    "\n",
    "for index in range(len(myst.index)):\n",
    "    distance, matches = nn_abs.kneighbors(myst_nn.iloc[[index]], 1, return_distance=True)\n",
    "    results_wine_nlp.append(\n",
    "        {\n",
    "            'Mystery': \"https://www.danmurphys.com.au/product/\" + str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Mystery Stockcode': str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Matched': \"https://www.danmurphys.com.au/product/\" + str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Matched Stockcode':  str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Distance': str(distance[0][0])\n",
    "            \n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "matched = pd.DataFrame(results_wine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-86-9f0de12e65a0>, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-9f0de12e65a0>\"\u001b[0;36m, line \u001b[0;32m82\u001b[0m\n\u001b[0;31m    https://www.danmurphys.com.au/product/DM_MYSTERY352/under-wraps-beechworth-sangiovese-2018\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#my_df_ohe.to_csv(\"OHE.csv\")\n",
    "#myst_nn = myst_nn.reset_index()\n",
    "#myst = myst.reset_index()\n",
    "\n",
    "#known_nn = known_nn.reset_index()\n",
    "#known = known.reset_index()\n",
    "\n",
    "##### Now myst\n",
    "#my_df_num_m = myst[exclude_col]\n",
    "#my_df_cat_m = myst.drop(exclude_col, axis=1)\n",
    "#my_df_cat.to_csv(\"FIN.csv\")\n",
    "#my_df_cat_ohe_m = pd.get_dummies(my_df_cat_m)\n",
    "#my_df_ohe_m = pd.concat([my_df_num_m,my_df_cat_ohe_m], axis=1)\n",
    "#my_df_ohe_m = my_df_ohe_m.drop(\"Stockcode\", axis=1)\n",
    "#my_df_ohe_m = my_df_ohe_m.fillna(0)\n",
    "#my_df_ohe_m = my_df_ohe_m.replace(np.nan, 0)\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# Create the k-NN model using k=5\n",
    "nn_abs = NearestNeighbors(n_neighbors=5, algorithm='auto')\n",
    "\n",
    "\n",
    "# Checkif we've got NsNS\n",
    "\n",
    "#\n",
    "#wines_corr =  my_df_ohe_d.corr(method = \"pearson\")\n",
    "#\n",
    "nn_abs.fit(known_nn)\n",
    "\n",
    "distance, matches = nn_abs.kneighbors(myst_nn.iloc[[9]], 2, return_distance=True)\n",
    "#matches\n",
    "\n",
    "known[\"Stockcode\"].iloc[matches[0]]\n",
    "\n",
    "myst['Stockcode'].iloc[[9]]\n",
    "#Now, tokenise each descition.\n",
    "#MAGIC TIME\n",
    "\n",
    "myst.iloc[[9]].to_csv(\"myst.csv\")\n",
    "myst_nn.iloc[[9]].to_csv(\"myst_nn.csv\")\n",
    "\n",
    "\n",
    "\n",
    "known.iloc[matches[0]].to_csv(\"known.csv\")\n",
    "known_nn.iloc[matches[0]].to_csv(\"known_nn.csv\")\n",
    "\n",
    "results_wine = []\n",
    "\n",
    "for index in range(len(myst.index)):\n",
    "    distance, matches = nn_abs.kneighbors(myst_nn.iloc[[index]], 1, return_distance=True)\n",
    "    results_wine.append(\n",
    "        {\n",
    "            'Mystery': \"https://www.danmurphys.com.au/product/\" + str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Matched': \"https://www.danmurphys.com.au/product/\" + str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Distance': str(distance[0][0])\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "matched = pd.DataFrame(results_wine)\n",
    "\n",
    "#def create_clickable_id(id):\n",
    "#    url_template= '''<a href=\"../../link/to/{id}\" target=\"_blank\">{id}</a>'''.format(id=id)\n",
    "#    return url_template\n",
    "\n",
    "#matched['Mystery'] = matched['Mystery'].apply(create_clickable_id)\n",
    "#matched['Matched'] = matched['Matched'].apply(create_clickable_id)\n",
    "\n",
    "matched.to_html(\"matched.html\")\n",
    "\n",
    "matched.to_csv(\"matched_sat_1.csv\")\n",
    "\n",
    "matches = nn_abs.kneighbors(myst_nn.iloc[[3]], 2, return_distance=False)\n",
    "known[\"Stockcode\"].iloc[matches[0]]\n",
    "\n",
    "myst['Stockcode'].iloc[[3]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.danmurphys.com.au/product/DM_MYSTERY352/under-wraps-beechworth-sangiovese-2018\n",
    "\n",
    "https://www.danmurphys.com.au/product/7252\n",
    "\n",
    "\n",
    "## xgboost\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = known_nn\n",
    "Y = known['Stockcode']\n",
    "\n",
    "X_test = myst_nn\n",
    "Y_test = myst['Stockcode']\n",
    "\n",
    "# Dont need this if already cleaned ohe\n",
    "#X.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X.columns.values]\n",
    "\n",
    "\n",
    "#\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier(verbosity=2)\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Check it out now\n",
    "print(model)\n",
    "\n",
    "\n",
    "### NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "GaussianNB(priors=None)\n",
    "y_pred = clf.predict(X_test_std)\n",
    "## Now to predict\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "#y_pred holds the predicted label of your test set.\n",
    "## Finally time to see the accuracy of our estimator.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "pd.DataFrame(y_pred).to_csv(\"Pred_NB.CSV\")\n",
    "\n",
    "pd.DataFrame(Y_test).to_csv(\"Myst_NB.CSV\")Ansd t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
