{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stu/code/dans\n"
     ]
    }
   ],
   "source": [
    "%cd /home/stu/code/dans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import xlrd\n",
    "import os\n",
    "from datetime import datetime, date, timedelta\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import nltk\n",
    "#from flatten_json import flatten\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_explode(file_res = \"API_results_\" + time.strftime(\"%Y%m%d\") + \".csv\"):\n",
    "    \n",
    "    #file_res = \"API_results_20210823.csv\"\n",
    "    my_df = pd.read_csv(file_res)\n",
    "\n",
    "    ## Categories\n",
    "    #my_df[\"Categories\"]\n",
    "    # Willnjust keep 2 levels.\n",
    "    my_df[\"Categories\"] = my_df[\"Categories\"].map(eval, na_action='ignore')\n",
    "    new_df = my_df[\"Categories\"].apply(pd.Series)\n",
    "    my_df[\"Categories\"] = new_df[0].apply(pd.Series).UrlFriendlyName\n",
    "    my_df[\"Sub_Categories\"] = new_df[1].apply(pd.Series).UrlFriendlyName\n",
    "\n",
    "    ## Reviews\n",
    "    my_df[\"Reviews\"] = my_df[\"Reviews\"].map(eval,  na_action='ignore')\n",
    "    # Try with first 2 reviews\n",
    "    new_df = my_df[\"Reviews\"].apply(pd.Series)\n",
    "    # First\n",
    "    my_df[\"Review1_auth\"] = new_df[0].apply(pd.Series).author.apply(pd.Series).Value\n",
    "    my_df[\"Review1_authorcontent\"] = new_df[0].apply(pd.Series).authorcontent.apply(pd.Series).Value\n",
    "    my_df[\"Review1_points\"] = new_df[0].apply(pd.Series).points.apply(pd.Series).Value\n",
    "    my_df[\"Review1_source\"] = new_df[0].apply(pd.Series).source.apply(pd.Series).Value\n",
    "    my_df[\"Review1_text\"] = new_df[0].apply(pd.Series).text.apply(pd.Series).Value\n",
    "    my_df[\"Review1_vintage\"] = new_df[0].apply(pd.Series).vintage.apply(pd.Series).Value\n",
    "    # Second\n",
    "    my_df[\"Review2_auth\"] = new_df[1].apply(pd.Series).author.apply(pd.Series).Value\n",
    "    my_df[\"Review2_authorcontent\"] = new_df[1].apply(pd.Series).authorcontent.apply(pd.Series).Value\n",
    "    my_df[\"Review2_points\"] = new_df[1].apply(pd.Series).points.apply(pd.Series).Value\n",
    "    my_df[\"Review2_source\"] = new_df[1].apply(pd.Series).source.apply(pd.Series).Value\n",
    "    my_df[\"Review2_text\"] = new_df[1].apply(pd.Series).text.apply(pd.Series).Value\n",
    "    my_df[\"Review2_vintage\"] = new_df[1].apply(pd.Series).vintage.apply(pd.Series).Value\n",
    "    \n",
    "    # Illl make a deep copy for later\n",
    "    full_df = copy.deepcopy(my_df)\n",
    "    #full_df = full_df\n",
    "    \n",
    "\n",
    "    # Additional details\n",
    "    my_df[\"AdditionalDetails\"] = my_df[\"AdditionalDetails\"].map(eval,  na_action='ignore')\n",
    "        # Can't use nested lists of JSON objects in pd.json_normalize\n",
    "    my_df = my_df.explode(column=\"AdditionalDetails\").reset_index(drop=True)\n",
    "    \n",
    "  \n",
    "    # Hacky, but it works... so we wont be touching this stuff!\n",
    "    add_df = pd.DataFrame(pd.json_normalize(my_df[\"AdditionalDetails\"]))\n",
    "    del add_df[\"DisplayName\"]\n",
    "    df = pd.concat([my_df,add_df],axis=1)\n",
    "    df = df.pivot(index='Stockcode',columns='Name', values='Value').reset_index().drop_duplicates(subset=['Stockcode'], keep=False)\n",
    "\n",
    "    # Check point, and also a way to get rid of headers\n",
    "    newdf = pd.merge(full_df, df, on='Stockcode')\n",
    "    #newdf = newdf.drop_duplicates(subset=['Stockcode'], keep=False)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 107 fields in line 11647, saw 144\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9385fb419b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_n_explode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"API_results_20210904.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-503e2e3f51c6>\u001b[0m in \u001b[0;36mload_n_explode\u001b[0;34m(file_res)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#file_res = \"API_results_20210823.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmy_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m## Categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 107 fields in line 11647, saw 144\n"
     ]
    }
   ],
   "source": [
    "wide = load_n_explode(\"API_results_20210904.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveaway(df):\n",
    "    gives = df.copy(deep=True)\n",
    "    gives = gives[['Stockcode','Description','webproductname','Prices.singleprice.Value','Prices.promoprice.Value','Prices.promoprice.BeforePromotion','Prices.promoprice.AfterPromotion','IsForDelivery']]\n",
    "    gives = gives[gives.webproductname.notnull()]\n",
    "    gives = gives[gives[\"Description\"].str.contains(\"Wraps\")]\n",
    "    gives = gives[~gives[\"webproductname\"].str.contains(\"Wraps\")]\n",
    "    gives = gives[gives[\"IsForDelivery\"]]\n",
    "    gives[\"METHOD\"] = \"giveaway\"\n",
    "    return gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>Description</th>\n",
       "      <th>webproductname</th>\n",
       "      <th>Prices.singleprice.Value</th>\n",
       "      <th>Prices.promoprice.Value</th>\n",
       "      <th>Prices.promoprice.BeforePromotion</th>\n",
       "      <th>Prices.promoprice.AfterPromotion</th>\n",
       "      <th>IsForDelivery</th>\n",
       "      <th>METHOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>MYSTERY437</td>\n",
       "      <td>Under Wraps Western&lt;br&gt;Australia Cabernet... ...</td>\n",
       "      <td>Alkoomi Blackbutt Cabernet Merlot Cabernet Franc</td>\n",
       "      <td>59.99</td>\n",
       "      <td>30.0</td>\n",
       "      <td>59.99</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>MYSTERY411</td>\n",
       "      <td>Under Wraps Hawkes Bay Syrah&lt;br&gt;2010  750mL</td>\n",
       "      <td>Craggy Range Le Sol Syrah 2010</td>\n",
       "      <td>155.99</td>\n",
       "      <td>79.9</td>\n",
       "      <td>155.99</td>\n",
       "      <td>79.9</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>MYSTERY459</td>\n",
       "      <td>Under Wraps Great Southern&lt;br&gt;Cabernet Sauvig...</td>\n",
       "      <td>Forest Hill Block 5 Caberent Sauvignon</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>MYSTERY196</td>\n",
       "      <td>Under Wraps Yarra Valley&lt;br&gt;Chardonnay 2018  ...</td>\n",
       "      <td>Yarra Trail Yarra Valley Chardonnay 2016</td>\n",
       "      <td>31.99</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.99</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>MYSTERY378</td>\n",
       "      <td>Under Wraps Western&lt;br&gt;Australia Cabernet... ...</td>\n",
       "      <td>Peos Estate Cab Sauv</td>\n",
       "      <td>22.99</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.99</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>MYSTERY540</td>\n",
       "      <td>Under Wraps Clare Valley&lt;br&gt;Cabernet Sauvigno...</td>\n",
       "      <td>Jim Barry The Benbournie Cabernet Sauvignon 2014</td>\n",
       "      <td>35.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>MYSTERY242</td>\n",
       "      <td>Under Wraps Barossa Merlot&lt;br&gt;2017  750mL</td>\n",
       "      <td>Gibson My Darling Merlot 2014</td>\n",
       "      <td>24.99</td>\n",
       "      <td>14.9</td>\n",
       "      <td>24.99</td>\n",
       "      <td>14.9</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>MYSTERY594</td>\n",
       "      <td>Under Wraps Heathcote Shiraz&lt;br&gt;Cabernet 2017...</td>\n",
       "      <td>Feathered Friends Heathcote Shiraz Cabernet 2015</td>\n",
       "      <td>25.00</td>\n",
       "      <td>89.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>89.0</td>\n",
       "      <td>True</td>\n",
       "      <td>giveaway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Stockcode                                        Description  \\\n",
       "727   MYSTERY437   Under Wraps Western<br>Australia Cabernet... ...   \n",
       "772   MYSTERY411        Under Wraps Hawkes Bay Syrah<br>2010  750mL   \n",
       "951   MYSTERY459   Under Wraps Great Southern<br>Cabernet Sauvig...   \n",
       "2215  MYSTERY196   Under Wraps Yarra Valley<br>Chardonnay 2018  ...   \n",
       "3706  MYSTERY378   Under Wraps Western<br>Australia Cabernet... ...   \n",
       "3863  MYSTERY540   Under Wraps Clare Valley<br>Cabernet Sauvigno...   \n",
       "3879  MYSTERY242          Under Wraps Barossa Merlot<br>2017  750mL   \n",
       "4116  MYSTERY594   Under Wraps Heathcote Shiraz<br>Cabernet 2017...   \n",
       "\n",
       "                                        webproductname  \\\n",
       "727   Alkoomi Blackbutt Cabernet Merlot Cabernet Franc   \n",
       "772                     Craggy Range Le Sol Syrah 2010   \n",
       "951             Forest Hill Block 5 Caberent Sauvignon   \n",
       "2215          Yarra Trail Yarra Valley Chardonnay 2016   \n",
       "3706                              Peos Estate Cab Sauv   \n",
       "3863  Jim Barry The Benbournie Cabernet Sauvignon 2014   \n",
       "3879                     Gibson My Darling Merlot 2014   \n",
       "4116  Feathered Friends Heathcote Shiraz Cabernet 2015   \n",
       "\n",
       "      Prices.singleprice.Value  Prices.promoprice.Value  \\\n",
       "727                      59.99                     30.0   \n",
       "772                     155.99                     79.9   \n",
       "951                      30.00                      NaN   \n",
       "2215                     31.99                     15.0   \n",
       "3706                     22.99                     15.0   \n",
       "3863                     35.88                      NaN   \n",
       "3879                     24.99                     14.9   \n",
       "4116                     25.00                     89.0   \n",
       "\n",
       "      Prices.promoprice.BeforePromotion  Prices.promoprice.AfterPromotion  \\\n",
       "727                               59.99                              30.0   \n",
       "772                              155.99                              79.9   \n",
       "951                                 NaN                               NaN   \n",
       "2215                              31.99                              15.0   \n",
       "3706                              22.99                              15.0   \n",
       "3863                                NaN                               NaN   \n",
       "3879                              24.99                              14.9   \n",
       "4116                             150.00                              89.0   \n",
       "\n",
       "      IsForDelivery    METHOD  \n",
       "727            True  giveaway  \n",
       "772            True  giveaway  \n",
       "951            True  giveaway  \n",
       "2215           True  giveaway  \n",
       "3706           True  giveaway  \n",
       "3863           True  giveaway  \n",
       "3879           True  giveaway  \n",
       "4116           True  giveaway  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#newdf.to_csv(\"newdf.csv\")\n",
    "giveaway(wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_ohe =['Categories',\n",
    " 'Description',\n",
    " 'Stockcode',\n",
    " 'PackageSize',\n",
    " 'Prices.inanysixprice.Message',\n",
    " 'Prices.inanysixprice.Value',\n",
    " 'Sub_Categories',\n",
    " 'Review1_auth',\n",
    " 'Review1_points',\n",
    " 'Review1_source',\n",
    " 'awardwinner',\n",
    " 'glutenfree',\n",
    " 'preservativefree',\n",
    " 'varietal',\n",
    " 'webalcoholpercentage',\n",
    " 'webbottleclosure',\n",
    " 'webcountryoforigin',\n",
    " 'webfoodmatch',\n",
    " 'webisorganic',\n",
    " 'webisvegan',\n",
    " 'webliquorsize',\n",
    " 'webmaincategory',\n",
    " 'webregionoforigin',\n",
    " 'webstateoforigin',\n",
    " 'webtotalreviewcount',\n",
    " 'webwinebody',\n",
    " 'webwinestyle',\n",
    " 'IsForDelivery']                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_nlp =['Categories',\n",
    " 'Stockcode',\n",
    " 'PackageSize',\n",
    " 'RichDescription',\n",
    " 'Review1_text',\n",
    " 'Review2_text',\n",
    " 'Prices.inanysixprice.Message',\n",
    " 'Prices.inanysixprice.Value',\n",
    " 'Sub_Categories',\n",
    " 'Review1_auth',\n",
    " 'Review1_points',\n",
    " 'Review1_source',\n",
    " 'awardwinner',\n",
    " 'glutenfree',\n",
    " 'preservativefree',\n",
    " 'varietal',\n",
    " 'webalcoholpercentage',\n",
    " 'webbottleclosure',\n",
    " 'webcountryoforigin',\n",
    " 'webdescriptionshort',\n",
    " 'webfoodmatch',\n",
    " 'webisorganic',\n",
    " 'webisvegan',\n",
    " 'webliquorsize',\n",
    " 'webmaincategory',\n",
    " 'webregionoforigin',\n",
    " 'webstateoforigin',\n",
    " 'webtotalreviewcount',\n",
    " 'webwinebody',\n",
    " 'webwinestyle',\n",
    " 'IsForDelivery']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wineknn(df, dist, keep):\n",
    "    kept = df.copy(deep=True)\n",
    "    kept = kept[keep]\n",
    "    kept.reset_index(drop=True, inplace=True)\n",
    "    # Known (its really just Kept...)\n",
    "    #known = kept\n",
    "    #known.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Split\n",
    "    myst = kept[kept[\"Description\"].str.contains(\"Wraps\")]\n",
    "    known = kept[~kept[\"Description\"].str.contains(\"Wraps\")]\n",
    "    #myst  = my_df_ohe[my_df_ohe.Stockcode.str.contains(\"MYSTERY\")]\n",
    "    #known  = my_df_ohe[~my_df_ohe.Stockcode.str.contains(\"MYSTERY\")]\n",
    "\n",
    "    myst = myst.drop(\"Description\", axis=1)\n",
    "    known = known.drop(\"Description\", axis=1)\n",
    "    \n",
    "    #### ONE HOT ENCODED\n",
    "\n",
    "    ##### First I split into numeric and nominal. OHE the nominal\n",
    "    exclude_col = known.select_dtypes(include=np.number).columns.tolist() + [\"Stockcode\"] \n",
    "    my_df_num = known[exclude_col]\n",
    "    my_df_cat = known.drop(exclude_col, axis=1)\n",
    "    #my_df_cat.to_csv(\"FIN.csv\")\n",
    "    my_df_cat_ohe = pd.get_dummies(my_df_cat)\n",
    "    my_df_ohe = pd.concat([my_df_num,my_df_cat_ohe], axis=1)\n",
    "    my_df_ohe = my_df_ohe.fillna(0)\n",
    "    my_df_ohe = my_df_ohe.replace(np.nan, 0)\n",
    "\n",
    "    # Drop duplicates #TODO check whats better to keep\n",
    "    my_df_ohe = my_df_ohe.loc[:,~my_df_ohe.columns.duplicated()]\n",
    "    # Clean up names\n",
    "    my_df_ohe.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in my_df_ohe.columns.values]\n",
    "\n",
    "    ##### First I split into numeric and nominal. OHE the nominal\n",
    "    myst_exclude_col = myst.select_dtypes(include=np.number).columns.tolist() + [\"Stockcode\"] \n",
    "    myst_my_df_num = myst[myst_exclude_col]\n",
    "    myst_my_df_cat = myst.drop(myst_exclude_col, axis=1)\n",
    "    #my_df_cat.to_csv(\"FIN.csv\")\n",
    "    myst_my_df_cat_ohe = pd.get_dummies(myst_my_df_cat)\n",
    "    myst_my_df_ohe = pd.concat([myst_my_df_num,myst_my_df_cat_ohe], axis=1)\n",
    "    myst_my_df_ohe = myst_my_df_ohe.fillna(0)\n",
    "    myst_my_df_ohe = myst_my_df_ohe.replace(np.nan, 0)\n",
    "\n",
    "    # Drop duplicates #TODO check whats better to keep\n",
    "    myst_my_df_ohe = myst_my_df_ohe.loc[:,~myst_my_df_ohe.columns.duplicated()]\n",
    "    # Clean up names\n",
    "    myst_my_df_ohe.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in myst_my_df_ohe.columns.values]\n",
    "\n",
    "    myst_nn = myst_my_df_ohe\n",
    "    known_nn = my_df_ohe\n",
    "\n",
    "    myst_nn = myst.drop(\"Stockcode\", axis=1)\n",
    "    known_nn = known.drop(\"Stockcode\", axis=1)\n",
    " \n",
    "   \n",
    "    # Create the k-NN model using k=5\n",
    "    nn_abs = NearestNeighbors(n_neighbors=1, algorithm='auto')\n",
    "\n",
    "    # Fit it\n",
    "    nn_abs.fit(known_nn)\n",
    "    \n",
    "    # Now lets us it in a loop\n",
    "    results_wine = []\n",
    "\n",
    "    for index in range(len(myst.index)):\n",
    "        distance, matches = nn_abs.kneighbors(myst_nn.iloc[[index]], 1, return_distance=True)\n",
    "        results_wine.append(\n",
    "            {\n",
    "                #'Mystery': \"https://www.danmurphys.com.au/product/\" + str(myst['Stockcode'].iloc[[index][0]]),\n",
    "                'Mystery Stockcode': str(myst['Stockcode'].iloc[[index][0]]),\n",
    "                #'Matched': \"https://www.danmurphys.com.au/product/\" + str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "                'Matched Stockcode':  str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "                'Distance': str(distance[0][0])\n",
    "\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    matched = pd.DataFrame(results_wine)\n",
    "    \n",
    "    #And bring back the details\n",
    "    promos = df[df.Stockcode.str.contains(\"MYSTERY\")][['Stockcode','webproductname','Prices.singleprice.Value','Prices.promoprice.Value','IsForDelivery']]\n",
    "    cutdown = df[['Stockcode','Description','producttitle']]\n",
    "    #Now to join them again\n",
    "    final = pd.merge(matched, promos, left_on='Mystery Stockcode', right_on='Stockcode')\n",
    "    final = pd.merge(final, cutdown, left_on='Matched Stockcode', right_on='Stockcode')\n",
    "    final =  final[final[\"IsForDelivery\"]]\n",
    "    final = final[[\"Mystery Stockcode\",\"Matched Stockcode\",\"Distance\",\"webproductname\",\"Prices.singleprice.Value\",\"Prices.promoprice.Value\",\"Description\",\"producttitle\"]]\n",
    "    final[\"METHOD\"] = \"knn\"\n",
    "    final['Savings'] = final[\"Prices.singleprice.Value\"] - final[\"Prices.promoprice.Value\"]\n",
    "    final[\"MatchLevel\"] = np.where(final['Distance'].astype(float) < float(dist), \"Good\", \"Poor\")\n",
    "    final = final.sort_values(['MatchLevel', 'Savings'], ascending=[True, False])\n",
    "    final = final[final.MatchLevel.str.contains(\"Good\")]\n",
    "                                                             \n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'red-wine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-69633546a429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwineknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_ohe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e502d1639dff>\u001b[0m in \u001b[0;36mwineknn\u001b[0;34m(df, dist, keep)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Fit it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mnn_abs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_nn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Now lets us it in a loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \"\"\"\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'red-wine'"
     ]
    }
   ],
   "source": [
    "wineknn(wide,1.8, keep_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clickable(val):\n",
    "    # target _blank to open new window\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "final = final.style.format({'Mystery': make_clickable,'Matched': make_clickable,})\\\n",
    "                   .bar(subset=['Savings'], align='mid', color=['#5fba7d'])\\\n",
    "                   .bar(subset=['Savings'], align='mid', color=['#5fba7d'])\\\n",
    "                   .hide_index()\\\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#final = final.style.format({'Mystery': make_clickable,'Matched': make_clickable,})\n",
    "#final = final.style.format({'Matched': make_clickable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing HTML Content\n",
    "heading = '<h1> Matched wines</h1>'\n",
    "subheading = '<h3> Results sub header </h3>'\n",
    "# Using .now() from datetime library to add Time stamp\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "header = '<div class=\"top\">' + heading + subheading +'</div>'\n",
    "footer = '<div class=\"bottom\"> <h3> This Report has been Generated on'+ current_time +'</h3> </div>'\n",
    "content = final\n",
    "# Concating everything to a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = header + content.render() + footer\n",
    "# Writing the file\n",
    "with open('report.html','w+') as file:\n",
    "    file.write(html)\n",
    "    #file.write(content)\n",
    "    #file.write(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Styler' object has no attribute 'to_html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b095a27a560d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Styler' object has no attribute 'to_html'"
     ]
    }
   ],
   "source": [
    "#final.to_html(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = \"Matched_results_\" + time.strftime(\"%Y%m%d\") + \".html\"\n",
    "f=open(final_res,\"w\")\n",
    "f.write(final.render()) # df is the styled dataframe\n",
    "f.close()\n",
    "#final.to_html(final_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now any easy ones just matching descirptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kept = wide[keep_nlp]\n",
    "kept = wide\n",
    "#kept.to_csv('fri_big_run_kept.csv')\n",
    "#newdf['Review1_text'] = wide['Review1_text']\n",
    "#newdf['Review2_text'] = wide['Review2_text']\n",
    "\n",
    "kept.reset_index(drop=True, inplace=True)\n",
    "myst  = kept[kept.Stockcode.str.contains(\"MYSTERY\")]\n",
    "known  = kept[~kept.Stockcode.str.contains(\"MYSTERY\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode_x</th>\n",
       "      <th>Stockcode_y</th>\n",
       "      <th>Description_y</th>\n",
       "      <th>Prices.singleprice.Value_x</th>\n",
       "      <th>Prices.promoprice.Value_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MYSTERY406</td>\n",
       "      <td>900159</td>\n",
       "      <td>Alkoomi Frankland River&lt;br&gt;Shiraz Viognier......</td>\n",
       "      <td>21.99</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MYSTERY561</td>\n",
       "      <td>802692</td>\n",
       "      <td>Shark Point Mornington&lt;br&gt;Peninsula Pinot... ...</td>\n",
       "      <td>34.99</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MYSTERY535</td>\n",
       "      <td>76922</td>\n",
       "      <td>Byron &amp; Harold Terrane&lt;br&gt;Margaret River... 7...</td>\n",
       "      <td>31.99</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MYSTERY463</td>\n",
       "      <td>75897</td>\n",
       "      <td>Richard Hamilton Colton's&lt;br&gt;Mclaren Vale Gsm...</td>\n",
       "      <td>21.99</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MYSTERY544</td>\n",
       "      <td>63658</td>\n",
       "      <td>Austins &amp; Co. Geelong Shiraz&lt;br&gt;2016  750mL</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MYSTERY405</td>\n",
       "      <td>56028</td>\n",
       "      <td>Willoughby Park Great&lt;br&gt;Southern Park... 750mL</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MYSTERY568</td>\n",
       "      <td>60717</td>\n",
       "      <td>Epic Negociants Black Label&lt;br&gt;The Ridge Marg...</td>\n",
       "      <td>44.99</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stockcode_x Stockcode_y                                      Description_y  \\\n",
       "0  MYSTERY406      900159   Alkoomi Frankland River<br>Shiraz Viognier......   \n",
       "1  MYSTERY561      802692   Shark Point Mornington<br>Peninsula Pinot... ...   \n",
       "2  MYSTERY535       76922   Byron & Harold Terrane<br>Margaret River... 7...   \n",
       "3  MYSTERY463       75897   Richard Hamilton Colton's<br>Mclaren Vale Gsm...   \n",
       "4  MYSTERY544       63658        Austins & Co. Geelong Shiraz<br>2016  750mL   \n",
       "5  MYSTERY405       56028    Willoughby Park Great<br>Southern Park... 750mL   \n",
       "6  MYSTERY568       60717   Epic Negociants Black Label<br>The Ridge Marg...   \n",
       "\n",
       "   Prices.singleprice.Value_x  Prices.promoprice.Value_x  \n",
       "0                       21.99                       14.9  \n",
       "1                       34.99                       15.0  \n",
       "2                       31.99                       15.0  \n",
       "3                       21.99                       10.0  \n",
       "4                       30.00                        NaN  \n",
       "5                        8.00                        NaN  \n",
       "6                       44.99                       20.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_match = pd.merge(myst[myst['RichDescription'].notna()], known, on=['RichDescription'], how='inner')\n",
    "#list(desc_match.columns)\n",
    "desc_match[[\"Stockcode_x\",\"Stockcode_y\",\"Description_y\",\"Prices.singleprice.Value_x\",\"Prices.promoprice.Value_x\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdesc_match = pd.merge(myst[myst['webdescriptionshort'].notna()], known, on=['webdescriptionshort'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_match = pd.merge(myst[myst['Review1_text'].notna()], known, on=['Review1_text'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev1_match = pd.merge(myst[myst['Review2_text'].notna()], known, on=['Review2_text'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = desc_match.append(webdesc_match).append(rev_match).append(rev1_match).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = text_match[['Stockcode_x','Stockcode_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode_x</th>\n",
       "      <th>Stockcode_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MYSTERY406</td>\n",
       "      <td>900159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MYSTERY561</td>\n",
       "      <td>802692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MYSTERY535</td>\n",
       "      <td>76922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MYSTERY463</td>\n",
       "      <td>75897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MYSTERY544</td>\n",
       "      <td>63658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>MYSTERY390</td>\n",
       "      <td>ER_1000005327_UWCTGREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>MYSTERY390</td>\n",
       "      <td>ER_1000006171_UWBDX18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>MYSTERY390</td>\n",
       "      <td>ER_2000003439_MORV-17-SHZ-BAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>MYSTERY390</td>\n",
       "      <td>ER_2000003952_CCAVMVS16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>MYSTERY351</td>\n",
       "      <td>58559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Stockcode_x                    Stockcode_y\n",
       "0     MYSTERY406                         900159\n",
       "1     MYSTERY561                         802692\n",
       "2     MYSTERY535                          76922\n",
       "3     MYSTERY463                          75897\n",
       "4     MYSTERY544                          63658\n",
       "...          ...                            ...\n",
       "4661  MYSTERY390        ER_1000005327_UWCTGREEN\n",
       "4662  MYSTERY390          ER_1000006171_UWBDX18\n",
       "4663  MYSTERY390  ER_2000003439_MORV-17-SHZ-BAR\n",
       "4664  MYSTERY390        ER_2000003952_CCAVMVS16\n",
       "4665  MYSTERY351                          58559\n",
       "\n",
       "[4666 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Now just need to join back with the stockcode, and we've got a working MVP..\n",
    "#promos = newdf[newdf.Stockcode.str.contains(\"MYSTERY\")][['Stockcode','webproductname','Prices.singleprice.Value','Prices.promoprice.Value']]\n",
    "#cutdown = newdf[['Stockcode','Description','producttitle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = pd.merge(text_match, wide, left_on='Stockcode_x', right_on='Stockcode')[['Stockcode_x','Stockcode_y','Description', 'Prices.singleprice.Value','Prices.promoprice.Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = pd.merge(text_match, wide, left_on='Stockcode_y', right_on='Stockcode')[['Stockcode_x','Stockcode_y','Description_y', 'Prices.singleprice.Value_x','Prices.promoprice.Value_x']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match['Savings'] = text_match[\"Prices.singleprice.Value_x\"] - text_match[\"Prices.promoprice.Value_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match = text_match.sort_values(['Savings'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_match.to_csv(\"Text_match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode_x</th>\n",
       "      <th>Stockcode_y</th>\n",
       "      <th>Description_y</th>\n",
       "      <th>Prices.singleprice.Value_x</th>\n",
       "      <th>Prices.promoprice.Value_x</th>\n",
       "      <th>Savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>MYSTERY265</td>\n",
       "      <td>ER_2000003981_UWBHVMSHIRAZ19</td>\n",
       "      <td>Under Wraps Mclaren Vale&lt;br&gt;Shiraz 2019  750mL</td>\n",
       "      <td>318.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>MYSTERY265</td>\n",
       "      <td>ER_2000003442_9352510000250</td>\n",
       "      <td>Under Wraps South Australian&lt;br&gt;Rose  750mL</td>\n",
       "      <td>318.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>MYSTERY265</td>\n",
       "      <td>ER_1000002961_JELRIE20</td>\n",
       "      <td>Under Wraps Eden Valley&lt;br&gt;Riesling 2020  750ml</td>\n",
       "      <td>318.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>MYSTERY265</td>\n",
       "      <td>ER_1000006495_UWAPOMVCAB19</td>\n",
       "      <td>Under Wraps Mclaren Vale&lt;br&gt;Cabernet Sauvigno...</td>\n",
       "      <td>318.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>MYSTERY265</td>\n",
       "      <td>ER_1000003887_UW-196917</td>\n",
       "      <td>Under Wraps Margaret River&lt;br&gt;Cabernet Sauvig...</td>\n",
       "      <td>318.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>MYSTERY210</td>\n",
       "      <td>ER_1000003887_UW-201525</td>\n",
       "      <td>Under Wraps Great Southern&lt;br&gt;Cabernet Sauvig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>MYSTERY458</td>\n",
       "      <td>ER_1000003887_UW-201525</td>\n",
       "      <td>Under Wraps Great Southern&lt;br&gt;Cabernet Sauvig...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>MYSTERY390</td>\n",
       "      <td>ER_1000003887_UW-201525</td>\n",
       "      <td>Under Wraps Great Southern&lt;br&gt;Cabernet Sauvig...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655</th>\n",
       "      <td>MYSTERY390</td>\n",
       "      <td>ER_2000003952_CCAVMVS16</td>\n",
       "      <td>Under Wraps Mclaren Vale&lt;br&gt;Shiraz 2016  750mL</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>MYSTERY319</td>\n",
       "      <td>672366</td>\n",
       "      <td>Torbreck Descendant Barossa&lt;br&gt;Valley Shiraz ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4666 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Stockcode_x                   Stockcode_y  \\\n",
       "293   MYSTERY265  ER_2000003981_UWBHVMSHIRAZ19   \n",
       "2882  MYSTERY265   ER_2000003442_9352510000250   \n",
       "4187  MYSTERY265        ER_1000002961_JELRIE20   \n",
       "2219  MYSTERY265    ER_1000006495_UWAPOMVCAB19   \n",
       "1534  MYSTERY265       ER_1000003887_UW-196917   \n",
       "...          ...                           ...   \n",
       "4642  MYSTERY210       ER_1000003887_UW-201525   \n",
       "4645  MYSTERY458       ER_1000003887_UW-201525   \n",
       "4646  MYSTERY390       ER_1000003887_UW-201525   \n",
       "4655  MYSTERY390       ER_2000003952_CCAVMVS16   \n",
       "4663  MYSTERY319                        672366   \n",
       "\n",
       "                                          Description_y  \\\n",
       "293      Under Wraps Mclaren Vale<br>Shiraz 2019  750mL   \n",
       "2882        Under Wraps South Australian<br>Rose  750mL   \n",
       "4187    Under Wraps Eden Valley<br>Riesling 2020  750ml   \n",
       "2219   Under Wraps Mclaren Vale<br>Cabernet Sauvigno...   \n",
       "1534   Under Wraps Margaret River<br>Cabernet Sauvig...   \n",
       "...                                                 ...   \n",
       "4642   Under Wraps Great Southern<br>Cabernet Sauvig...   \n",
       "4645   Under Wraps Great Southern<br>Cabernet Sauvig...   \n",
       "4646   Under Wraps Great Southern<br>Cabernet Sauvig...   \n",
       "4655     Under Wraps Mclaren Vale<br>Shiraz 2016  750mL   \n",
       "4663   Torbreck Descendant Barossa<br>Valley Shiraz ...   \n",
       "\n",
       "      Prices.singleprice.Value_x  Prices.promoprice.Value_x  Savings  \n",
       "293                        318.0                       65.0    253.0  \n",
       "2882                       318.0                       65.0    253.0  \n",
       "4187                       318.0                       65.0    253.0  \n",
       "2219                       318.0                       65.0    253.0  \n",
       "1534                       318.0                       65.0    253.0  \n",
       "...                          ...                        ...      ...  \n",
       "4642                         NaN                        NaN      NaN  \n",
       "4645                         8.0                        NaN      NaN  \n",
       "4646                         6.0                        NaN      NaN  \n",
       "4655                         6.0                        NaN      NaN  \n",
       "4663                         5.0                        NaN      NaN  \n",
       "\n",
       "[4666 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_match\n",
    "#Try Fuzzy\n",
    "#https://towardsdatascience.com/how-to-do-fuzzy-matching-in-python-pandas-dataframe-6ce3025834a6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to try and do the NLP Work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text to TFIDF\n",
    "#'webdescriptionshort',\n",
    "#'RichDescription',\n",
    "keep1 =['Stockcode',\n",
    " 'webdescriptionshort',\n",
    "'RichDescription']     \n",
    "#keep1 =[\n",
    "# 'webdescriptionshort',\n",
    "#'RichDescription','Review1_text','Review2_text']     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = newdf[keep1]\n",
    "#kept.to_csv('fri_big_run_kept.csv')\n",
    "kept.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "myst_nn  = kept[kept.Stockcode.str.contains(\"MYSTERY\")]\n",
    "known_nn  = kept[~kept.Stockcode.str.contains(\"MYSTERY\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using http://mlbernauer.github.io/R/20160131-document-retrieval-sklearn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding in tfidf for description, and then dropping the columns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#transformer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "#v = TfidfVectorizer(ngram_range=(2, 3))\n",
    "#x = v.fit_transform(kept['RichDescription'].values.astype('U'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer for webdescriptionshort, max_df is set to 0.5, we only want\n",
    "# to include terms that appear in less tha 50% of the documents (i.e. rare terms)\n",
    "web_tfidf_vectorizer = TfidfVectorizer(max_features=1000000, use_idf=True,ngram_range=(1, 3))\n",
    "\n",
    "# Create vectorizer for , RichDescriptions max_df is set to 0.5, we only want \n",
    "# to include terms that appear in less than 50% of the documents (i.e. rare terms)\n",
    "rich_tfidf_vectorizer = TfidfVectorizer(max_features=1000000, use_idf=True,ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Weights for both\n",
    "tfidf_weights_web = web_tfidf_vectorizer.fit_transform(kept['webdescriptionshort'].values.astype('U'))\n",
    "tfidf_weights_rich = rich_tfidf_vectorizer.fit_transform(kept['RichDescription'].values.astype('U'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names for Abstract and Title models\n",
    "tfidf_features_web = web_tfidf_vectorizer.get_feature_names()\n",
    "tfidf_features_rich = rich_tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model to return 5 closest neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Create the k-NN model using k=5\n",
    "nn_web = NearestNeighbors(n_neighbors=1, algorithm='auto')\n",
    "nn_rich = NearestNeighbors(n_neighbors=1, algorithm='auto')\n",
    "\n",
    "# Fit the models to the TF-IDF weights matrix\n",
    "nn_fitted_web = nn_web.fit(tfidf_weights_web)\n",
    "nn_fitted_rich = nn_rich.fit(tfidf_weights_rich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_papers(row, kNNmodel, tfidf_weights, tfidf_features, papers):\n",
    "    #keywords = get_top_features(row, tfidf_weights, tfidf_features)\n",
    "    dist,idx = kNNmodel.kneighbors(tfidf_weights[row,:])\n",
    "    idx = list(idx[0])\n",
    "    return {'Wines':kept.iloc[idx]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(rownum, weights, features, top_k=10):\n",
    "    weight_vec = weights.toarray()[rownum,:]\n",
    "    top_idx = np.argsort(weight_vec)[::-1][:top_k]\n",
    "    return [features[i] for i in top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1115], dtype='int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept.index[kept['Stockcode'] == 'MYSTERY265']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1115], dtype='int64')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept.index[kept['Stockcode'] == 'MYSTERY265']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([5354], dtype='int64')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.index[df['Stockcode'] == 'MYSTERY265']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>webdescriptionshort</th>\n",
       "      <th>RichDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>MYSTERY265</td>\n",
       "      <td>&lt;p&gt;The fruit for this iconic wine is handpicke...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Stockcode                                webdescriptionshort  \\\n",
       "1115  MYSTERY265  <p>The fruit for this iconic wine is handpicke...   \n",
       "\n",
       "     RichDescription  \n",
       "1115             NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find_nearest_papers(1, nn_fitted_abs, tfidf_weights_abs, tfidf_features_abs, papers)['papers']\n",
    "find_nearest_papers(1115, nn_fitted_web, tfidf_weights_web, tfidf_features_web, kept)['Wines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>webdescriptionshort</th>\n",
       "      <th>RichDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>943434</td>\n",
       "      <td>Dark and focused, filled with juicy and vibran...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stockcode                                webdescriptionshort  \\\n",
       "54    943434  Dark and focused, filled with juicy and vibran...   \n",
       "\n",
       "   RichDescription  \n",
       "54             NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find_nearest_papers(1, nn_fitted_abs, tfidf_weights_abs, tfidf_features_abs, papers)['papers']\n",
    "find_nearest_papers(1115, nn_fitted_rich, tfidf_weights_rich, tfidf_features_rich, kept)['Wines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wine_nlp = []\n",
    "\n",
    "for index in range(len(myst.index)):\n",
    "    distance, matches = nn_abs.kneighbors(myst_nn.iloc[[index]], 1, return_distance=True)\n",
    "    results_wine_nlp.append(\n",
    "        {\n",
    "            'Mystery': \"https://www.danmurphys.com.au/product/\" + str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Mystery Stockcode': str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Matched': \"https://www.danmurphys.com.au/product/\" + str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Matched Stockcode':  str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Distance': str(distance[0][0])\n",
    "            \n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "matched = pd.DataFrame(results_wine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-86-9f0de12e65a0>, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-9f0de12e65a0>\"\u001b[0;36m, line \u001b[0;32m82\u001b[0m\n\u001b[0;31m    https://www.danmurphys.com.au/product/DM_MYSTERY352/under-wraps-beechworth-sangiovese-2018\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#my_df_ohe.to_csv(\"OHE.csv\")\n",
    "#myst_nn = myst_nn.reset_index()\n",
    "#myst = myst.reset_index()\n",
    "\n",
    "#known_nn = known_nn.reset_index()\n",
    "#known = known.reset_index()\n",
    "\n",
    "##### Now myst\n",
    "#my_df_num_m = myst[exclude_col]\n",
    "#my_df_cat_m = myst.drop(exclude_col, axis=1)\n",
    "#my_df_cat.to_csv(\"FIN.csv\")\n",
    "#my_df_cat_ohe_m = pd.get_dummies(my_df_cat_m)\n",
    "#my_df_ohe_m = pd.concat([my_df_num_m,my_df_cat_ohe_m], axis=1)\n",
    "#my_df_ohe_m = my_df_ohe_m.drop(\"Stockcode\", axis=1)\n",
    "#my_df_ohe_m = my_df_ohe_m.fillna(0)\n",
    "#my_df_ohe_m = my_df_ohe_m.replace(np.nan, 0)\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# Create the k-NN model using k=5\n",
    "nn_abs = NearestNeighbors(n_neighbors=5, algorithm='auto')\n",
    "\n",
    "\n",
    "# Checkif we've got NsNS\n",
    "\n",
    "#\n",
    "#wines_corr =  my_df_ohe_d.corr(method = \"pearson\")\n",
    "#\n",
    "nn_abs.fit(known_nn)\n",
    "\n",
    "distance, matches = nn_abs.kneighbors(myst_nn.iloc[[9]], 2, return_distance=True)\n",
    "#matches\n",
    "\n",
    "known[\"Stockcode\"].iloc[matches[0]]\n",
    "\n",
    "myst['Stockcode'].iloc[[9]]\n",
    "#Now, tokenise each descition.\n",
    "#MAGIC TIME\n",
    "\n",
    "myst.iloc[[9]].to_csv(\"myst.csv\")\n",
    "myst_nn.iloc[[9]].to_csv(\"myst_nn.csv\")\n",
    "\n",
    "\n",
    "\n",
    "known.iloc[matches[0]].to_csv(\"known.csv\")\n",
    "known_nn.iloc[matches[0]].to_csv(\"known_nn.csv\")\n",
    "\n",
    "results_wine = []\n",
    "\n",
    "for index in range(len(myst.index)):\n",
    "    distance, matches = nn_abs.kneighbors(myst_nn.iloc[[index]], 1, return_distance=True)\n",
    "    results_wine.append(\n",
    "        {\n",
    "            'Mystery': \"https://www.danmurphys.com.au/product/\" + str(myst['Stockcode'].iloc[[index][0]]),\n",
    "            'Matched': \"https://www.danmurphys.com.au/product/\" + str(known[\"Stockcode\"].iloc[matches[0][0]]),\n",
    "            'Distance': str(distance[0][0])\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "matched = pd.DataFrame(results_wine)\n",
    "\n",
    "#def create_clickable_id(id):\n",
    "#    url_template= '''<a href=\"../../link/to/{id}\" target=\"_blank\">{id}</a>'''.format(id=id)\n",
    "#    return url_template\n",
    "\n",
    "#matched['Mystery'] = matched['Mystery'].apply(create_clickable_id)\n",
    "#matched['Matched'] = matched['Matched'].apply(create_clickable_id)\n",
    "\n",
    "matched.to_html(\"matched.html\")\n",
    "\n",
    "matched.to_csv(\"matched_sat_1.csv\")\n",
    "\n",
    "matches = nn_abs.kneighbors(myst_nn.iloc[[3]], 2, return_distance=False)\n",
    "known[\"Stockcode\"].iloc[matches[0]]\n",
    "\n",
    "myst['Stockcode'].iloc[[3]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.danmurphys.com.au/product/DM_MYSTERY352/under-wraps-beechworth-sangiovese-2018\n",
    "\n",
    "https://www.danmurphys.com.au/product/7252\n",
    "\n",
    "\n",
    "## xgboost\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = known_nn\n",
    "Y = known['Stockcode']\n",
    "\n",
    "X_test = myst_nn\n",
    "Y_test = myst['Stockcode']\n",
    "\n",
    "# Dont need this if already cleaned ohe\n",
    "#X.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X.columns.values]\n",
    "\n",
    "\n",
    "#\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier(verbosity=2)\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Check it out now\n",
    "print(model)\n",
    "\n",
    "\n",
    "### NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "GaussianNB(priors=None)\n",
    "y_pred = clf.predict(X_test_std)\n",
    "## Now to predict\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "#y_pred holds the predicted label of your test set.\n",
    "## Finally time to see the accuracy of our estimator.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "pd.DataFrame(y_pred).to_csv(\"Pred_NB.CSV\")\n",
    "\n",
    "pd.DataFrame(Y_test).to_csv(\"Myst_NB.CSV\")Ansd t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
